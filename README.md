The workshop covers the following sessions:
* TensorFlow vs PyTorch: differences at the level of memory layout, data loading, training loops, graphs and practical examples comparing training and inference results of the same model.
* Tensors: covering properties, expressivity, common operations, usage hints, relations to numpy and practical examples.
* Autograd: understand how it enables us to train networks from a deep dive into how weights get adjusted, computation graphs and functions to efficient computation through Jacobian products.
* Data Handling: Explains concepts such as relevant design patterns, datasets, dataloaders, collation, data transforms and gives a practical example implementing a simple ACC system.
* CUDA: Introduces the CUDA programming model accompanied by CUDA C examples and finally rebuilding the linear layer from CUDA C all the way up to PyTorch and use it to train a simple NN.